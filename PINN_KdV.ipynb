{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a39a89c-a4e8-44b3-9e58-8669c185621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 9.899e-01, l1: 0.749, l2: 0.00248\n",
      "Iteration 10, Loss: 9.577e-01, l1: 0.739, l2: 0.00251\n",
      "Iteration 20, Loss: 9.317e-01, l1: 0.730, l2: 0.00253\n",
      "Iteration 30, Loss: 8.464e-01, l1: 0.737, l2: 0.00256\n",
      "Iteration 40, Loss: 8.149e-01, l1: 0.728, l2: 0.00260\n",
      "Iteration 50, Loss: 7.734e-01, l1: 0.720, l2: 0.00263\n",
      "Iteration 60, Loss: 7.285e-01, l1: 0.714, l2: 0.00266\n",
      "Iteration 70, Loss: 6.959e-01, l1: 0.715, l2: 0.00269\n",
      "Iteration 80, Loss: 6.697e-01, l1: 0.721, l2: 0.00271\n",
      "Iteration 90, Loss: 6.413e-01, l1: 0.732, l2: 0.00274\n",
      "Iteration 100, Loss: 6.046e-01, l1: 0.744, l2: 0.00277\n",
      "Iteration 110, Loss: 5.365e-01, l1: 0.757, l2: 0.00281\n",
      "Iteration 120, Loss: 4.878e-01, l1: 0.772, l2: 0.00279\n",
      "Iteration 130, Loss: 4.757e-01, l1: 0.782, l2: 0.00275\n",
      "Iteration 140, Loss: 4.676e-01, l1: 0.792, l2: 0.00271\n",
      "Iteration 150, Loss: 4.558e-01, l1: 0.802, l2: 0.00268\n",
      "Iteration 160, Loss: 4.469e-01, l1: 0.812, l2: 0.00265\n",
      "Iteration 170, Loss: 4.401e-01, l1: 0.822, l2: 0.00262\n",
      "Iteration 180, Loss: 4.343e-01, l1: 0.831, l2: 0.00259\n",
      "Iteration 190, Loss: 4.291e-01, l1: 0.840, l2: 0.00257\n",
      "Iteration 200, Loss: 4.246e-01, l1: 0.849, l2: 0.00254\n",
      "Iteration 210, Loss: 4.206e-01, l1: 0.858, l2: 0.00252\n",
      "Iteration 220, Loss: 4.170e-01, l1: 0.866, l2: 0.00250\n",
      "Iteration 230, Loss: 4.135e-01, l1: 0.874, l2: 0.00248\n",
      "Iteration 240, Loss: 4.100e-01, l1: 0.882, l2: 0.00247\n",
      "Iteration 250, Loss: 4.065e-01, l1: 0.890, l2: 0.00245\n",
      "Iteration 260, Loss: 4.028e-01, l1: 0.897, l2: 0.00244\n",
      "Iteration 270, Loss: 3.991e-01, l1: 0.904, l2: 0.00243\n",
      "Iteration 280, Loss: 3.990e-01, l1: 0.910, l2: 0.00242\n",
      "Iteration 290, Loss: 3.905e-01, l1: 0.916, l2: 0.00241\n",
      "Iteration 300, Loss: 3.837e-01, l1: 0.921, l2: 0.00240\n",
      "Iteration 310, Loss: 3.919e-01, l1: 0.926, l2: 0.00240\n",
      "Iteration 320, Loss: 3.644e-01, l1: 0.931, l2: 0.00240\n",
      "Iteration 330, Loss: 3.591e-01, l1: 0.935, l2: 0.00240\n",
      "Iteration 340, Loss: 3.561e-01, l1: 0.939, l2: 0.00239\n",
      "Iteration 350, Loss: 3.513e-01, l1: 0.943, l2: 0.00239\n",
      "Iteration 360, Loss: 3.483e-01, l1: 0.948, l2: 0.00239\n",
      "Iteration 370, Loss: 3.450e-01, l1: 0.952, l2: 0.00239\n",
      "Iteration 380, Loss: 3.490e-01, l1: 0.955, l2: 0.00239\n",
      "Iteration 390, Loss: 3.457e-01, l1: 0.958, l2: 0.00239\n",
      "Iteration 400, Loss: 3.417e-01, l1: 0.962, l2: 0.00239\n",
      "Iteration 410, Loss: 3.355e-01, l1: 0.965, l2: 0.00239\n",
      "Iteration 420, Loss: 3.319e-01, l1: 0.969, l2: 0.00239\n",
      "Iteration 430, Loss: 3.281e-01, l1: 0.973, l2: 0.00239\n",
      "Iteration 440, Loss: 3.236e-01, l1: 0.977, l2: 0.00239\n",
      "Iteration 450, Loss: 3.190e-01, l1: 0.981, l2: 0.00239\n",
      "Iteration 460, Loss: 3.144e-01, l1: 0.985, l2: 0.00239\n",
      "Iteration 470, Loss: 3.475e-01, l1: 0.987, l2: 0.00240\n",
      "Iteration 480, Loss: 3.156e-01, l1: 0.989, l2: 0.00240\n",
      "Iteration 490, Loss: 3.094e-01, l1: 0.992, l2: 0.00240\n",
      "Identified lambda_1: 0.9943400025367737\n",
      "Identified lambda_2: 0.0024001896381378174\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "class PhysicsInformedNN(nn.Module):\n",
    "    def __init__(self, x0, u0, x1, u1, layers, dt, lb, ub, q):\n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "        self.lb = torch.tensor(lb, dtype=torch.float32)\n",
    "        self.ub = torch.tensor(ub, dtype=torch.float32)\n",
    "        \n",
    "        self.x0 = torch.tensor(x0, dtype=torch.float32, requires_grad=True)\n",
    "        self.x1 = torch.tensor(x1, dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        self.u0 = torch.tensor(u0, dtype=torch.float32)\n",
    "        self.u1 = torch.tensor(u1, dtype=torch.float32)\n",
    "        \n",
    "        self.dt = torch.tensor(dt, dtype=torch.float32)\n",
    "        self.q = max(q, 1)\n",
    "\n",
    "        # Initialize NN\n",
    "        self.model = self.build_nn(layers)\n",
    "        \n",
    "        # Parameters to be learned\n",
    "        self.lambda_1 = nn.Parameter(torch.tensor(0.75))\n",
    "        self.lambda_2 = nn.Parameter(torch.tensor(-6.0))\n",
    "\n",
    "        # IRK weights\n",
    "        tmp = np.float32(np.loadtxt('IRK_weights/Butcher_IRK%d.txt' % (q), ndmin=2))\n",
    "        weights = np.reshape(tmp[0:q**2+q], (q+1, q))\n",
    "        self.IRK_alpha = torch.tensor(weights[0:-1, :], dtype=torch.float32)\n",
    "        self.IRK_beta = torch.tensor(weights[-1:, :], dtype=torch.float32)\n",
    "        self.IRK_times = torch.tensor(tmp[q**2+q:], dtype=torch.float32)\n",
    "\n",
    "    def build_nn(self, layers):\n",
    "        modules = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            modules.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "            if i < len(layers) - 2:\n",
    "                modules.append(nn.Tanh())\n",
    "        return nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * (x - self.lb) / (self.ub - self.lb) - 1.0\n",
    "        return self.model(x)\n",
    "\n",
    "    def fwd_gradients(self, U, x):\n",
    "        return torch.autograd.grad(U, x, grad_outputs=torch.ones_like(U), create_graph=True)[0]\n",
    "\n",
    "    def net_U0(self, x):\n",
    "        U = self.forward(x)\n",
    "        U_x = self.fwd_gradients(U, x)\n",
    "        U_xx = self.fwd_gradients(U_x, x)\n",
    "        U_xxx = self.fwd_gradients(U_xx, x)\n",
    "\n",
    "        F = -self.lambda_1 * U * U_x - torch.exp(self.lambda_2) * U_xxx\n",
    "        U0 = U - self.dt * torch.matmul(F, self.IRK_alpha.T)\n",
    "        return U0\n",
    "\n",
    "    def net_U1(self, x):\n",
    "        U = self.forward(x)\n",
    "        U_x = self.fwd_gradients(U, x)\n",
    "        U_xx = self.fwd_gradients(U_x, x)\n",
    "        U_xxx = self.fwd_gradients(U_xx, x)\n",
    "\n",
    "        F = -self.lambda_1 * U * U_x - torch.exp(self.lambda_2) * U_xxx\n",
    "        U1 = U + self.dt * torch.matmul(F, (self.IRK_beta - self.IRK_alpha).T)\n",
    "        return U1\n",
    "\n",
    "    def loss_fn(self):\n",
    "        U0_pred = self.net_U0(self.x0)\n",
    "        U1_pred = self.net_U1(self.x1)\n",
    "\n",
    "        loss = torch.mean((self.u0 - U0_pred) ** 2) + torch.mean((self.u1 - U1_pred) ** 2)\n",
    "        return loss\n",
    "\n",
    "    def train(self, nIter):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        for it in range(nIter):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss_fn()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if it % 10 == 0:\n",
    "                print(f\"Iteration {it}, Loss: {loss.item():.3e}, l1: {self.lambda_1.item():.3f}, l2: {torch.exp(self.lambda_2).item():.5f}\")\n",
    "\n",
    "    def predict(self, x_star):\n",
    "        x_star = torch.tensor(x_star, dtype=torch.float32, requires_grad=True)\n",
    "        U0_pred = self.net_U0(x_star)\n",
    "        U1_pred = self.net_U1(x_star)\n",
    "        return U0_pred.detach().numpy(), U1_pred.detach().numpy()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = 50\n",
    "    skip = 120\n",
    "\n",
    "    N0 = 199\n",
    "    N1 = 201\n",
    "    layers = [1, 50, 50, 50, 50, q]\n",
    "\n",
    "    data = scipy.io.loadmat('KdV.mat')\n",
    "\n",
    "    t_star = data['tt'].flatten()[:, None]\n",
    "    x_star = data['x'].flatten()[:, None]\n",
    "    Exact = np.real(data['uu'])\n",
    "\n",
    "    idx_t = 40\n",
    "\n",
    "    noise = 0.01\n",
    "    idx_x = np.random.choice(Exact.shape[0], N0, replace=False)\n",
    "    x0 = x_star[idx_x, :]\n",
    "    u0 = Exact[idx_x, idx_t][:, None]\n",
    "    u0 += noise * np.std(u0) * np.random.randn(*u0.shape)\n",
    "\n",
    "    idx_x = np.random.choice(Exact.shape[0], N1, replace=False)\n",
    "    x1 = x_star[idx_x, :]\n",
    "    u1 = Exact[idx_x, idx_t + skip][:, None]\n",
    "    u1 += noise * np.std(u1) * np.random.randn(*u1.shape)\n",
    "\n",
    "    dt = t_star[idx_t + skip] - t_star[idx_t]\n",
    "\n",
    "    lb = x_star.min(0)\n",
    "    ub = x_star.max(0)\n",
    "\n",
    "    model = PhysicsInformedNN(x0, u0, x1, u1, layers, dt, lb, ub, q)\n",
    "    model.train(nIter=500)\n",
    "\n",
    "    U0_pred, U1_pred = model.predict(x_star)\n",
    "\n",
    "    lambda_1_value = model.lambda_1.item()\n",
    "    lambda_2_value = torch.exp(model.lambda_2).item()\n",
    "\n",
    "    print(f\"Identified lambda_1: {lambda_1_value}\")\n",
    "    print(f\"Identified lambda_2: {lambda_2_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26dfef3d-19d2-4af9-9ed8-be11c9325a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error lambda_1: 0.566000%\n",
      "Error lambda_2: 3.992414%\n"
     ]
    }
   ],
   "source": [
    "error_lambda_1 = np.abs(lambda_1_value - 1.0)/1.0 *100\n",
    "error_lambda_2 = np.abs(lambda_2_value - 0.0025)/0.0025 * 100\n",
    "    \n",
    "print('Error lambda_1: %f%%' % (error_lambda_1))\n",
    "print('Error lambda_2: %f%%' % (error_lambda_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00e68f-9dce-408a-ab7a-afa3d593ff97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
